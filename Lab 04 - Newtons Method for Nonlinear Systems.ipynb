{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Newton's Method for Nonlinear Systems\n",
        "\n",
        "### Topics\n",
        "\n",
        "- **Mathematics:**  multidimensional Newton's method; estimating errors when solving linear systems; condition number; numerical calculation of the Jacobian.\n",
        "- **Python:** using Numpy's `np.linalg.solve` to solve linear systems; generalising an function for single-variable Newton's method to multidimensional Newton's method; testing for convergence of a sequence of vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=130) #set the line width so wider arrays don't get wrapped\n",
        "import scipy.linalg #we will need the hilbert function from here\n",
        "\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numpy's function for solving linear systems\n",
        "\n",
        "Numpy has a way to solve $A\\underline{\\mathbf{x}} = \\underline{\\mathbf{b}}$ using the `np.linalg.solve` function.  For example:\n",
        "```\n",
        "x = np.linalg.solve(A, b)\n",
        "```\n",
        "Mathematically, this is equivalent to $\\underline{\\mathbf{x}} = A^{-1} \\underline{\\mathbf{b}}$ (although Numpy doesn't actually work out the inverse matrix $A^{-1}$ as this is less efficient and has more issues with round-off error).\n",
        "\n",
        "In this lab we'll use Numpy's function.\n",
        "\n",
        "## Multidimensional Newton's method\n",
        "\n",
        "We want to find a solution to the following nonlinear system of equations\n",
        "\\begin{align*}\n",
        "  x_2 &= \\ln x_1, \\\\\n",
        "  x_2 &= \\frac{1}{25}(x_1^2 +2x_1-24).\n",
        "\\end{align*}\n",
        "First, rearrange this system into the form $\\underline{\\mathbf{f}}(\\underline{\\mathbf{x}}) = 0$ on paper, and write down the Jacobian matrix $J$ associated with the system.\n",
        "\n",
        "Define a function `f` that takes in a vector `x` and returns the value of $\\underline{\\mathbf{f}}$ as a **1-dimensional** Numpy array, and another function `J` that takes in a vector `x` and returns the value of $J$, as a Numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.25  1.  ]\n",
            " [-0.4   1.  ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=130) #set the line width so wider arrays don't get wrapped\n",
        "import scipy.linalg #we will need the hilbert function from here\n",
        "\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x):\n",
        "    return(np.array([x[1] - (1/25) * (x[0]**2 - 2*x[0] + 24) , x[1] - np.log(x[0])]))\n",
        "    \n",
        "def J(x):\n",
        "    return(np.array([[-1/x[0], 1],[1/25*(-2*x[0]-2),1]]))\n",
        "\n",
        "x= [4,2]\n",
        "\n",
        "print(J(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now look at your Newton's method function `newt` from Lab 2.  You should have a version that tests for convergence to some tolerance `tol` which begins\n",
        "```\n",
        "def newt(x, num_iter, func, deriv, tol=1e-4):\n",
        "```\n",
        "where `x` is the initial approximation to the solution, `num_iter` is the maximum number of iterations to carry out, `func` and `deriv` are the function to solve with and its derivative, and `tol` is the desired tolerance.\n",
        "\n",
        "You are going to use this function as a template for doing multidimensional Newton's method.  Copy it into the cell below, rename it `multinewt`, and rename the `deriv` parameter to `jacobian`.  Now, modify the function so that it solves a **system** of equations, rather than just a single equation.  Remember, the key difference is that the variables $\\underline{\\mathbf{x}}$ and $\\underline{\\mathbf{f}}$ are now vectors and, instead of the derivative $\\frac{\\mathrm{d}f}{\\mathrm{d}x}$, we now have a Jacobian matrix $J$.  The parts of the function that you need to modify are:\n",
        "- `f` will now be the **vector** function you are trying to find the zeros of.\n",
        "- Instead of `dfdx = ...`, you now need to define `J` to be the results of `jacobian(x)`.\n",
        "- The **change** $\\Delta\\underline{\\mathbf{x}}$ in $\\underline{\\mathbf{x}}$ at each iteration of Newton's method is the solution of the linear system $J\\Delta\\underline{\\mathbf{x}} = -\\underline{\\mathbf{f}}$.  Use Numpy's `np.linalg.solve` to solve for `dx`.  Then update the variable `x` by adding `dx`.\n",
        "- **Change** the line saving the current step to `results.append([k, *x, *f])`.  The `*` puts in the entries of the vector rather than the vector object, and will only work with 1-dimensional arrays or lists.\n",
        "\n",
        "**Hint:** Try to make sure your function will work solving systems of any dimension (i.e. don't make it only work for 2 components).\n",
        "\n",
        "Your function should now do the correct multidimensional Newton's method iterations.  However, you still need to modify the convergence test to account for the fact that you are using vectors instead of scalars.  So, instead of using the absolute value (`abs`), you now need to use the infinity norm (`np.linalg.norm(..., np.inf)`) to test whether\n",
        "\n",
        "$$\n",
        "  \\frac{\\left\\|\\underline{\\mathbf{x}}^{\\left(k+1\\right)}-\\underline{\\mathbf{x}}^{\\left(k\\right)}\\right\\|_\\infty}\n",
        "       {\\left\\|\\underline{\\mathbf{x}}^{\\left(k+1\\right)}\\right\\|_\\infty}\n",
        "    < \\mathtt{tol},\n",
        "$$\n",
        "\n",
        "where $\\underline{\\mathbf{x}}^{\\left(k\\right)}$ is the value of the vector $\\underline{\\mathbf{x}}$ after $k$ iterations.  Note that, by definition $\\Delta \\underline{\\mathbf{x}} = \\underline{\\mathbf{x}}^{\\left(k+1\\right)}-\\underline{\\mathbf{x}}^{\\left(k\\right)}$.\n",
        "\n",
        "Like your original Newton's method function, your new function should return all the iterations in a matrix called `results`.  The $k$th row of `results` should contain the values of `k` the vectors `x` and `f` after $k$ iterations.  Hopefully, the final row will contain the solution for `x`.\n",
        "\n",
        "<div class=\"alert alert-warning\">\n",
        "  <h3 style=\"margin-top: 0;\">Checkpoint 1</h3>\n",
        "\n",
        "  Use your function to find the solution(s) to the nonlinear system (there may be more than one!).  <b>Hint:</b> Use a graph to find suitable initial approximation(s) to the solution(s).\n",
        "  \n",
        "  Check that your answer seems reasonable.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2]\n",
            "[[2.08 0.  ]\n",
            " [7.75 0.  ]]\n",
            "[[2.08 0.  ]\n",
            " [7.75 0.  ]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Tarn Holt\\AppData\\Local\\Temp\\ipykernel_5652\\3511585908.py:9: RuntimeWarning: divide by zero encountered in log\n",
            "  return(np.array([x[1] - (1/25) * (x[0]**2 - 2*x[0] + 24) , x[1] - np.log(x[0])]))\n",
            "C:\\Users\\Tarn Holt\\AppData\\Local\\Temp\\ipykernel_5652\\3511585908.py:12: RuntimeWarning: divide by zero encountered in divide\n",
            "  return(np.array([[-1/x[0], 1],[1/25*(-2*x[0]-2),1]]))\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 2) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iterations reached. No convergence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(results)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmultinewt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36mmultinewt\u001b[1;34m(x0, func, jacobian, num_iter, tol)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x0)\n\u001b[1;32m---> 18\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m (x0 \u001b[38;5;241m-\u001b[39m func(x0) \u001b[38;5;241m/\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x1)\n\u001b[0;32m     20\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend([iteration, x1, func(x0)])\n",
            "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mJ\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mJ\u001b[39m(x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 2) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=130) #set the line width so wider arrays don't get wrapped\n",
        "import scipy.linalg #we will need the hilbert function from here\n",
        "\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x):\n",
        "    return(np.array([x[1] - (1/25) * (x[0]**2 - 2*x[0] + 24) , x[1] - np.log(x[0])]))\n",
        "    \n",
        "def J(x):\n",
        "    return(np.array([[-1/x[0], 1],[1/25*(-2*x[0]-2),1]]))\n",
        "\n",
        "def multinewt(x0,func , jacobian, num_iter=100, tol=1e-4):\n",
        "    results = []\n",
        "    for iteration in range(num_iter):\n",
        "        print(x0)\n",
        "        x1 = (x0 - func(x0) / jacobian(x0)).copy()\n",
        "        results.append([iteration, x1, func(x0)])\n",
        "        if np.linalg.norm(x1-x0, np.inf)/np.linalg.norm(x1, np.inf) < tol:\n",
        "            print(f\"Root found at {x0} after {iteration + 1} iterations.\")\n",
        "            return np.array(results)\n",
        "        x0 = x1.copy()\n",
        "    \n",
        "    print(\"Maximum number of iterations reached. No convergence.\")\n",
        "    return np.array(results)\n",
        "\n",
        "print(multinewt([1,2], f, J))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now take a bit of a detour into ill-conditioned matrices, as covered in lectures last week.\n",
        "\n",
        "## Errors when solving linear systems\n",
        "\n",
        "To assess the reliability of any equation solver, you need a way of checking the accuracy of a supposed solution $\\underline{\\mathbf{x}}_1$ to a linear system $A\\underline{\\mathbf{x}}=\\underline{\\mathbf{b}}$.  If we write $\\underline{\\mathbf{x}}$ for the exact solution, then what we'd really like to know is the size of:\n",
        "\n",
        "$$\n",
        "  \\begin{array}{lll}\n",
        "    & \\left\\|\\underline{\\mathbf{x}}-\\underline{\\mathbf{x}}_1\\right\\| & \\text{(the absolute error)}, \\\\\n",
        "    \\text{or } & \\left\\|\\underline{\\mathbf{x}}-\\underline{\\mathbf{x}}_1\\right\\|/\\left\\|\\underline{\\mathbf{x}}\\right\\| & \\text{(the relative error)}.\n",
        "  \\end{array}\n",
        "$$\n",
        "\n",
        "In real life, of course, we do not know what $\\underline{\\mathbf{x}}$ is, so we cannot calculate these numbers.  However, we can use this strategy if we test the equation solver on equations with known solutions.  Such equations are easily constructed.\n",
        "\n",
        "Start with any non-singular $2 \\times 2$ matrix $A$ and vector $\\underline{\\mathbf{x}}$ and define $\\underline{\\mathbf{b}}$ by $\\underline{\\mathbf{b}}=A\\underline{\\mathbf{x}}$ â€“ remember to use `@` for matrix multiplication.  Now pretend you don't know what $\\underline{\\mathbf{x}}$ is.  Use the `np.linalg.solve` function to find Numpy's solution for $\\underline{\\mathbf{x}}$ using $A$ and $\\underline{\\mathbf{b}}$.\n",
        "\n",
        "**Hint:** Store the calculated solution in `x1` so you don't overwrite `x`.\n",
        "\n",
        "Calculate the absolute and relative errors compared to the exact solution $\\underline{\\mathbf{x}}$ (remember to use the infinity norm).  Are they zero? What does this tell you?\n",
        "\n",
        "Another way to check the accuracy of a supposed solution is to see how well $\\underline{\\mathbf{x}}_1$ fits the given system.  To do that we calculate $\\underline{\\mathbf{b}}_1 = A\\underline{\\mathbf{x}}_1$ and see if $\\underline{\\mathbf{b}}_1$ is close to $\\underline{\\mathbf{b}}$.  The difference $\\underline{\\mathbf{b}}-\\underline{\\mathbf{b}}_1$ is called the **residual vector**.  So we might hope that if the residual vector is small, then $\\underline{\\mathbf{x}}_1$ is a good approximation to the true solution $\\underline{\\mathbf{x}}$.  We measure the size of the residual vector by looking at the one of the following quantities:\n",
        "\n",
        "$$\n",
        "  \\begin{array}{lll} \n",
        "    & \\left\\|\\underline{\\mathbf{b}}-\\underline{\\mathbf{b}}_1\\right\\| & \\text{(the absolute residual)}, \\\\\n",
        "    \\text{or } & \\left\\|\\underline{\\mathbf{b}}-\\underline{\\mathbf{b}}_1\\right\\|/\\left\\|\\underline{\\mathbf{b}}\\right\\| & \\text{(the relative residual)}.\n",
        "  \\end{array}\n",
        "$$\n",
        "\n",
        "Calculate the absolute and relative residuals.  Are they zero?\n",
        "\n",
        "You will use both these checking methods, along with the condition number, in the following exercise.  Numpy has a built-in function `np.linalg.cond` which gives the **condition number** of a matrix.\n",
        "\n",
        "Write a function `errors` that calculates Numpy's solution (using `np.linalg.solve`) and works out the relative error and relative residual for a given matrix $A$ and known solution vector $\\underline{\\mathbf{x}}$.  `errors` should take a matrix `A` and solution vector `x` as parameters, and return the relative error, relative residual, and condition number:\n",
        "```\n",
        "return rel_error, rel_resid, cond\n",
        "```\n",
        "The multiple outputs (a tuple) can be assigned individual names when you call the function like this:\n",
        "```\n",
        "rel_error, rel_resid, cond = errors(A, x)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hilbert matrices\n",
        "\n",
        "Hilbert matrices are a badly conditioned type of matrix (that arise if you try to find least squares polynomial fits without using orthogonal polynomials).  Scipy has a function which sets up $n \\times n$ Hilbert matrices.  Run `scipy.linalg.hilbert?` to see how to get a Hilbert matrix.\n",
        "\n",
        "Define $A$ to be the $5 \\times 5$ Hilbert matrix, and $\\underline{\\mathbf{x}}$ to be a $5 \\times 1$ vector of 1's.\n",
        "\n",
        "Run `errors` to find the relative error, relative residual, and condition number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's investigate how the errors, residuals and condition number behave for different sized Hilbert matrices.  Below, write a function `hilbert_errors` that runs `errors` so that it calculates the relative error, the relative residual and the condition number for a series of Hilbert matrices of size $n = 2, 3, \\ldots$ up to size $n = 15$.\n",
        "\n",
        "Your function should store the results for each matrix as a row of numbers, `results = []` then `results.append(...)` (as you did in Lab 2), which should contain: the size of the matrix ($n$), the relative error, relative residual and condition number.\n",
        "\n",
        "**Hint:** You can make a list containing the elements of a tuple using `*` as we did above, e.g. `[n, *errors(...)]`.\n",
        "\n",
        "<div class=\"alert alert-warning\">\n",
        "  <h3 style=\"margin-top: 0;\">Checkpoint 2</h3>\n",
        "\n",
        "  <ul>\n",
        "    <li>What is the first value of $n$ for which the calculated solution is no longer accurate to 4 significant figures?</li>\n",
        "    <li>Are the residual vectors a good guide to the accuracy of the calculated solution?</li>\n",
        "    <li>Is the condition number a good guide to the accuracy of the calculated solution?</li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, back to multidimensional Newton's method.\n",
        "\n",
        "## Numerical approximation of the Jacobian\n",
        "\n",
        "We have already made a multimensional Newton's method that will work for any function (hopefully it will cope with a 3D system like the one below).  However, it requires a manually derived Jacobian function, which can be a lot of work.  We can instead make our function estimate the Jacobian numerically.  Copy your `multinewt` function into the cell below, and modify it so that it has a default `jacobian` parameter value of `None`, and to have an `h` parameter, like this:\n",
        "```\n",
        "def multinewt(x, num_iter, func, jacobian=None, tol=1e-4, h=1e-6):\n",
        "```\n",
        "Make your new function use a Jacobian function if one is passed in, and otherwise estimate the Jacobian matrix as follows.  The formula for calculating the partial derivative $\\partial f_i/\\partial x_j$ numerically is really the same as the formula for ordinary derivatives (which you used at the end of Lab 2):\n",
        "\n",
        "$$\n",
        "  \\frac{\\partial f_i}{\\partial x_j}\n",
        "    \\approx \\frac{f_i(x_1,\\ldots,x_j+h,\\ldots,x_n )-f_i(x_1,\\ldots,x_j,\\ldots,x_n)}{h}.\n",
        "$$\n",
        "\n",
        "This looks like you might need two two loops, go cover every element of the Jacobian matrix (and that will work), but actually you can do it a whole column at a time, since $f$ produces a vector output.  To do it column-by-column, you will need to evaluate $f$ at the current $x_k$ with $h$ added to one of the elements.  The easiest way to do that is to make a copy of `x` and modify it:\n",
        "```\n",
        "xh = x.copy()\n",
        "xh[i] += h\n",
        "```\n",
        "\n",
        "<div class=\"alert alert-warning\">\n",
        "  <h3 style=\"margin-top: 0;\">Checkpoint 3</h3>\n",
        "\n",
        "  Use your function to find the solution to the system\n",
        "  \\begin{align*}\n",
        "    x_1^2 - x_1 x_2 - 10 &= 0 \\\\\n",
        "    x_2 + 3x_1 x_2^2 - 57 &= 0 \\\\\n",
        "    x_1 + x_2 - 2x_3 &= 0\n",
        "  \\end{align*}\n",
        "  using an initial approximation of $\\underline{\\mathbf{x}} = (1.5, 3.5, 2.5)$.  Check that your answer gives a small residual.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
